import pandas as pd
import matplotlib.pyplot as plt
import streamlit as st
import numpy as np
import torch
import torchvision
import torch.nn as nn
from torchvision import transforms as T
from PIL import Image
import time
import urllib.request
from ultralytics import YOLO


st.page_link('pages/–ú–æ–∑–≥_–º–µ—Ç—Ä–∏–∫–∏_–º–æ–¥–µ–ª–∏.py', label='–£–∑–Ω–∞—Ç—å –¥–µ—Ç–∞–ª–∏ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏')
st.title('__–û–ø—Ä–µ–¥–µ–ª–∏—Ç–µ –æ–ø—É—Ö–æ–ª—å –ø–æ —Å–Ω–∏–º–∫—É –ú–†–¢!üß†__')

st.logo('./images/mri.jpg', icon_image='./images/brain.jpg', size='large')

DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'


model1 = YOLO('models/–ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–∞—è.pt')
model1.to(DEVICE)

model2 = YOLO('models/all_dataset.pt')
model2.to(DEVICE)

model3 = YOLO('models/lr_saggital.pt')
model3.to(DEVICE)

model4 = YOLO('models/lr_coronal.pt')
model4.to(DEVICE)

model5 = YOLO('models/axial_lr.pt')
model5.to(DEVICE)

def get_prediction(img, model) -> int:
    start = time.time()
    results = model.predict(img) # –ü–æ–ª—É—á–∞–µ–º –≤—ã–≤–æ–¥ –º–æ–¥–µ–ª–∏
    end = time.time()
    pred_images = [result.plot() for result in results]
    return end-start, pred_images

if 'predictions' not in st.session_state:
    st.session_state.predictions = []

st.write('##### <- –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Å–Ω–∏–º–æ–∫ –ú–†–¢ –≤ —Å–∞–≥–≥–∏—Ç–∞–ª—å–Ω–æ–π, –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω–æ–π –∏–ª–∏ —Ñ—Ä–æ–Ω—Ç–∞–ª—å–Ω–æ–π –ø—Ä–æ–µ–∫—Ü–∏—è—Ö, –∫–∞–∫ –Ω–∞ –ø—Ä–∏–º–µ—Ä–µ:')
ex_image = Image.open('images/example.jpg')
st.image(ex_image)

uploaded_file = st.sidebar.file_uploader(label='–ó–∞–≥—Ä—É–∂–∞—Ç—å —Å–Ω–∏–º–æ–∫ —Å—é–¥–∞:', type=['jpeg', 'png'], accept_multiple_files=True)

model = None


st.write('–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å')
if st.button('–û–±—É—á–µ–Ω–Ω–∞—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ –Ω–∞ —Ä–∞–∑–Ω—ã—Ö –ø—Ä–æ–µ–∫—Ü–∏—è—Ö'):
    model = model1
if st.button('–û–±—É—á–µ–Ω–Ω–∞—è –Ω–∞ –≤—Å–µ—Ö –ø—Ä–æ–µ–∫—Ü–∏—è—Ö —Å—Ä–∞–∑—É'):
    model = model2
if st.button('–ú–æ–¥–µ–ª—å –¥–ª—è —Å–∞–≥–≥–∏—Ç–∞–ª—å–Ω–æ–π –ø—Ä–æ–µ–∫—Ü–∏–∏'):
    model = model3
if st.button('–ú–æ–¥–µ–ª—å –¥–ª—è —Ñ—Ä–æ–Ω—Ç–∞–ª—å–Ω–æ–π –ø—Ä–æ–µ–∫—Ü–∏–∏'):
    model = model4
if st.button('–ú–æ–¥–µ–ª—å –¥–ª—è –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω–æ–π –ø—Ä–æ–µ–∫—Ü–∏–∏'):
    model = model5

if uploaded_file is not None:
    for file in uploaded_file:
        image = Image.open(file)
        if model is not None:
            sec, results = get_prediction(image, model)
            st.write(f'''–í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: __{sec:.4f} —Å–µ–∫—É–Ω–¥—ã__ 
        \n–†–µ–∑—É–ª—å—Ç–∞—Ç –¥–µ—Ç–µ–∫—Ü–∏–∏:''')
            st.image(results, use_container_width=True)
        

link = st.sidebar.text_input(label='–í—Å—Ç–∞–≤—å—Ç–µ —Å—é–¥–∞ —Å—Å—ã–ª–∫—É –Ω–∞ —Å–Ω–∏–º–æ–∫')
if link is not '':
    image = Image.open(urllib.request.urlopen(link)).convert("RGB")
    if model is not None:
        sec, results = get_prediction(image, model)
        st.write(f'''–í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: __{sec:.4f} —Å–µ–∫—É–Ω–¥—ã__ 
        \n–†–µ–∑—É–ª—å—Ç–∞—Ç –¥–µ—Ç–µ–∫—Ü–∏–∏:''')
        st.image(results, use_container_width=True)

